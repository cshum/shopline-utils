{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopline_import_multiplier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshum/shopline-utils/blob/main/shopline_import_multiplier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71g-uXpDwUh0"
      },
      "source": [
        "#Shopline Import Multiplier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwnMWbDz7owJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "#pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', 999)\n",
        "\n",
        "#input/output config\n",
        "xls_file = 'http://static.cshum.com.s3.amazonaws.com/shopline-utils/ProductBulkImportForm-2021-04-21-21_30.xls'\n",
        "image_filenames = 'http://static.cshum.com.s3.amazonaws.com/shopline-utils/1.txt'\n",
        "output_filename = 'shopline.xls'\n",
        "\n",
        "#image url: substitute template where suitable\n",
        "image_url_template = 'http://static.cshum.com.s3.amazonaws.com/shopline-utils/images/{filename}'\n",
        "image_url_substitute = '{filename}'\n",
        "image_sku_regex = '(.+)\\d{2}\\.[a-zA-Z]+$' #regex extract sku from filename\n",
        "image_seq_regex = '(\\d{2})\\.[a-zA-Z]+$' #regex extract sequence from filename\n",
        "\n",
        "#fields config\n",
        "group_field = 'Product Handle*'\n",
        "sku_field = 'Variation SKU'\n",
        "color_field = 'Variation name A(English)'\n",
        "image_field = 'Images*'\n",
        "\n",
        "\n",
        "def process(df):\n",
        "  #skip first row\n",
        "  df_first_row = df.loc[0].to_frame().T\n",
        "  df = df.iloc[1:].reset_index(drop=True).ffill()\n",
        "  #cleanup existing duped products\n",
        "  df = df.drop_duplicates(sku_field) \n",
        "  #group by product handle for processing\n",
        "  df = df.groupby(group_field).apply(process_group).reset_index(drop=True)\n",
        "  #restore first row\n",
        "  df = pd.concat([df_first_row, df]).reset_index(drop=True)\n",
        "  return df\n",
        "\n",
        "\n",
        "def process_group(df):\n",
        "  df = df.copy()\n",
        "  ln = df.shape[0]\n",
        "  l = df.index.to_list()\n",
        "  if ln <= 1:\n",
        "    return df\n",
        "  first_color = df.loc[0][color_field]\n",
        "  for i in range(1, ln):\n",
        "    #contine next row if color same as first color\n",
        "    if first_color == df.loc[l[i]][color_field]:\n",
        "      continue\n",
        "    #duplicate variants a,b,c then b,c,a then c,a,b\n",
        "    ps = l[i:] + l[0:i]\n",
        "    for idx in ps:\n",
        "      p = df.loc[idx].copy()\n",
        "      # append 002 003... to product handle to group duplications\n",
        "      p[group_field] = '{}{:0>3d}'.format(p[group_field], i+1)\n",
        "      df.loc[df.shape[0] + 1] = p\n",
        "  return df\n",
        "\n",
        "\n",
        "def transform_merge_images(df, df_images):\n",
        "  #excel left join images from images\n",
        "  df = df.merge(df_images, on=sku_field, how='left')\n",
        "  df[image_field] = df['images'].fillna(df[image_field])\n",
        "  del df['images']\n",
        "  return df\n",
        "\n",
        "\n",
        "def transform_filenames(df):\n",
        "  df = df.copy()\n",
        "  #extract sku, sequence, url from filenames list\n",
        "  df[sku_field] = df.filename.str.extract(image_sku_regex, expand=True)\n",
        "  df['seq'] = df.filename.str.extract(image_seq_regex, expand=True).astype(int)\n",
        "  df['url'] = df['filename'].apply(\n",
        "    lambda u: image_url_template.replace(image_url_substitute, u))\n",
        "  join_urls = lambda df: ','.join(df.sort_values(by='seq')['url'].to_list())\n",
        "  #return comma joined image urls group by sku\n",
        "  return df.groupby(sku_field).apply(join_urls).reset_index(name='images')\n",
        "\n",
        "\n",
        "df = pd.read_excel(xls_file)\n",
        "try:\n",
        "  df_filenames = pd.read_csv(image_filenames, names=['filename'])\n",
        "  df_images = transform_filenames(df_filenames)\n",
        "  df = transform_merge_images(df, df_images)\n",
        "except Exception as err:\n",
        "  traceback.print_tb(err.__traceback__)\n",
        "df = process(df)\n",
        "df.to_excel(output_filename, index=False)\n",
        "\n",
        "df.replace(np.nan, '') #cleanup nan for better display"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}